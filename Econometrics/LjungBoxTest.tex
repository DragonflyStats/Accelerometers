\section*{Ljung–Box Test}
The Ljung–Box test (named for Greta M. Ljung and George E. P. Box) is a type of statistical test of whether any of a group of autocorrelations of a time series are different from zero. Instead of testing randomness at each distinct lag, it tests the "overall" randomness based on a number of lags, and is therefore a \textbf{\textit{portmanteau test}}.
%===================================================%

This test is sometimes known as the Ljung–Box Q test, and it is closely connected to the Box–Pierce test (which is named after George E. P. Box and David A. Pierce). 

In fact, the Ljung–Box test statistic was described explicitly in the paper that led to the use of the Box-Pierce statistic,and from which that statistic takes its name. 

The Box-Pierce test statistic is a simplified version of the Ljung–Box statistic for which subsequent simulation studies have shown poor performance.
%===================================================%

The Ljung–Box test is widely applied in econometrics and other applications of time series analysis. A similar assessment can be also carried out with the Breusch–Godfrey test and the Durbin–Watson test.

%===================================================%
The Llung–Box test may be defined as:

\begin{description}
\item[H0:] The data are independently distributed (i.e. the correlations in the population from which the sample is taken are 0, so that any observed correlations in the data result from randomness of the sampling process).
\item[Ha:] The data are not independently distributed; they exhibit serial correlation.
\end{description}
%===================================================%
The test statistic is:

\[{\displaystyle Q=n\left(n+2\right)\sum _{k=1}^{h}{\frac {{\hat {\rho }}_{k}^{2}}{n-k}}} \]
\[Q = n\left(n+2\right)\sum_{k=1}^h\frac{\hat{\rho}^2_k}{n-k}\]
where n is the sample size, {\displaystyle {\hat {\rho }}_{k}} \hat{\rho}_k is the sample autocorrelation at lag k, and h is the number of lags being tested. Under {\displaystyle H_{0}} H_{0} the statistic Q follows a {\displaystyle \chi _{(h)}^{2}} \chi _{{(h)}}^{2}. For significance level α, the critical region for rejection of the hypothesis of randomness is.

\[{\displaystyle Q>\chi _{1-\alpha ,h}^{2}} \]
Q > \chi_{1-\alpha,h}^2
where {\displaystyle \chi _{1-\alpha ,h}^{2}} \chi_{1-\alpha,h}^2 is the α-quantile of the chi-squared distribution with h degrees of freedom.
%===================================================%

The Ljung–Box test is uncommonly used in autoregressive integrated moving average (ARIMA) modeling. Note that it is applied to the residuals of a fitted ARIMA model, not the original series, and in such applications the hypothesis actually being tested is that the residuals from the ARIMA model have no autocorrelation. 

%===================================================%

When testing the residuals of an estimated ARIMA model, the degrees of freedom need to be adjusted to reflect the parameter estimation. For example, for an ARIMA(p,0,q) model, the degrees of freedom should be set to {\displaystyle h-p-q} h-p-q.[3]

\subsection*{Box-Pierce test}
The Box-Pierce test uses the test statistic, in the notation outlined above, given by[1]

\[{\displaystyle Q_{\text{BP}}=n\sum _{k=1}^{h}{\hat {\rho }}_{k}^{2},} \] 
Q_\text{BP} = n \sum_{k=1}^h \hat{\rho}^2_k,
and it uses the same critical region as defined above.

Simulation studies have shown that the Ljung–Box statistic is better for all sample sizes including small ones.[citation needed]

\subsection*{Implementations in statistics packages}
R: the Box.test function in the stats package[4]
